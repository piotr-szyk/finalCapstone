'''
Data Science
TASK: Semantic Similarity (NLP)
Compulsory Task 1
Author: Piotr Szyk
Date: 30 May 2023
'''

import spacy
nlp = spacy.load("en_core_web_md")

word1 = nlp("cat")
word2 = nlp("monkey")
word3 = nlp("banana")

print("========== cat monkey banana example ==========")

print(word1.similarity(word2))
print(word3.similarity(word2))
print(word3.similarity(word1))

'''
1. Write a note about what you found interesting about the similarities
between cat, monkey and banana and think of an example of your own.

0.5929929675536907 <- cat and monkey
0.4041501317354622 <- banana and monkey
0.22358827466989753 <- banana and cat

The result indicate that cat and monkey have the highest
similarity, possible because both are animals.
As expected, banana and cat have lower similarity, however,
banana and monkey have higher similarity in comparison with
banana and cat. This could be explained by the fact that
monkeys are usually associated with bananas.
'''

# Own example with car, automobile and vehicle
word1 = nlp("car")
word2 = nlp("automobile")
word3 = nlp("vehicle")

print("========== car automobile vehicle example ==========")

print(word1.similarity(word2))
print(word3.similarity(word2))
print(word3.similarity(word1))

'''
0.6684950439284806 <- car and automobile
0.7693282898817417 <- vehicle and automobile
0.777999497899576  <- vehicle and car

As expected, all of the words show high similarity (much higher
than the cat, monkey, banana example), with the highest
between vehicle and car. I have selected words that are
closely related to see if the word vectors generated by spacy
accurately describe the similarities between the words.
'''

print("========== Working with Vectors==========")
tokens = nlp('cat apple monkey banana')

# Iterate over each token in the tokens list
for token1 in tokens:
    # Iterate over each token again to compare with token1
    for token2 in tokens:
        # Print the text and similarity between token1 and token2
        print(token1.text, token2.text, token1.similarity(token2))

print("========== Working with Sentences==========")

# The sentence to compare against
sentence_to_compare = "Why is my cat on the car"

# List of sentences to compare with the model_sentence
sentences = ["where did my dog go",
             "Hello, there is my car",
             "I\'ve lost my car in my car",
             "I\'d like my boat back",
             "I will name my dog Diana"]

# Process the model_sentence
model_sentence = nlp(sentence_to_compare)
print("Model sentence:",model_sentence)
# Iterate over each sentence in the sentences list
for sentence in sentences:
    # Calculate the similarity between the current sentence and the model_sentence
    similarity = nlp(sentence).similarity(model_sentence)

    # Print the sentence and its similarity score
    print(sentence + " - ",  similarity)

# Check which language models are installed with spacy
# print(spacy.info()["pipelines"].keys())

'''
2. Run the example file with the simpler language model 'en_core_web_sm'
and write a note on what you notice is different from the model 'en_core_web_md'.

When example.py is run with the simpler language model: en_core_web_sm,
a warning message is thrown, which suggests that this language model does
not have word vectors loaded. This means that similarity method will have to
depend on tagger, parser and named entity recognizer (NER), which may not
provide accurate or useful results. This is because the absence of word vectors
limits the ability to capture the finer nuances of word meanings and associations.

The original warning message is below:
UserWarning: [W007] The model you're using has no word vectors loaded,
so the result of the Doc.similarity method will be based on the tagger,
parser and NER, which may not give useful similarity judgements.
This may happen if you're using one of the small models, e.g. 'en_core_web_sm',
which don't ship with word vectors and only use context-sensitive tensors.
You can always add your own word vectors, or use one of the larger models
instead if available.
'''
